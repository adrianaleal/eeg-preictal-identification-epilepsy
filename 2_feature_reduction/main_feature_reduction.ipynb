{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyter_dash'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdash_bootstrap_components\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdbc\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdash\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdependencies\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input, Output\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjupyter_dash\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mJupyterDash\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01meeg_preictal_analysis\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EEGPreictalAnalysis\n\u001B[1;32m     16\u001B[0m eeg_class \u001B[38;5;241m=\u001B[39m EEGPreictalAnalysis()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'jupyter_dash'"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from dash import Dash, dcc, html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "import jupyter_dash as JupyterDash\n",
    "\n",
    "from eeg_preictal_analysis import EEGPreictalAnalysis\n",
    "eeg_class = EEGPreictalAnalysis()\n",
    "\n",
    "feature_group = 'Multivariate' # 'Multivariate' OR 'Univariate_linear' OR 'Univariate_nonlinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare data to run feature reduction\n",
    "patient_index = 112802\n",
    "seizure_index = 6\n",
    "pat_seiz_data_folder = 'patient' + str(patient_index) + '_seizure' + str(seizure_index)\n",
    "\n",
    "# get current working directory\n",
    "wd = os.getcwd()\n",
    "\n",
    "# define dictionary for saving prepared features (save_flag=1 to save and save_flag=0 otherwise)\n",
    "save_dict = {'save_flag': 0, 'save_folder': ''}\n",
    "\n",
    "# get time data\n",
    "df_datetime_vector, indexes_5min_win2remove = eeg_class.prepare_time_data4feat_reduction(patient_index, seizure_index, pat_seiz_data_folder, save_dict)\n",
    "df_datetime_vector.head()\n",
    "\n",
    "# load patient information to get seizure onset date\n",
    "eeg_onset_seizure = eeg_class.get_seizure_onset(patient_index, seizure_index)\n",
    "\n",
    "df_time_min, df_time_h = eeg_class.get_time_data(df_datetime_vector, 'win_start_date', eeg_onset_seizure)\n",
    "\n",
    "\n",
    "get_time_vector = 'min'\n",
    "\n",
    "if get_time_vector == 'min':\n",
    "    time_vec_minutes = df_time_min['time_min']\n",
    "    time_vector = time_vec_minutes*(-1)\n",
    "    tickvals_lst = [-10, -50, -100, -150, -200, time_vector[0]]\n",
    "    ticktext_lst = [-10, -50, -100, -150, -200, round(time_vector[0])]\n",
    "else:\n",
    "    time_vector = eeg_class.update_time_hour_night_transition(df_time_h)\n",
    "\n",
    "# prepare feature data for feature reduction\n",
    "df_seizure_data, original_feat_names, constant_feat_names, quasi_constant_feat_names = eeg_class.prepare_feature_data4feat_reduction(pat_seiz_data_folder, feature_group, indexes_5min_win2remove, save_dict)\n",
    "df_seizure_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply feature reduction, apply clustering methods and evaluate clustering solutions\n",
    "\n",
    "clust_methods = ['KMEANS_K2', 'KMEANS_K3', 'KMEANS_K4', 'AGGLO_HIER_K2', 'AGGLO_HIER_K3', 'AGGLO_HIER_K4', 'HDBSCAN0', 'GMM_K2', 'GMM_K3', 'GMM_K4']\n",
    "\n",
    "clust_eval = ['clust_method', 'n_clusters', 'noisy_clusters', 'n_samples_smaller_cluster', 'DI', 'SI', 'OD', 'CS', 'C', 'DBI']\n",
    "\n",
    "print(clust_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Principal Component Analysis (PCA):\n",
    "df_pca, pca = eeg_class.pca_feature_reduction(df_seizure_data)\n",
    "df_pca.head()\n",
    "distances_matrix = pairwise_distances(df_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply user input clustering method and plot results\n",
    "\n",
    "# decided to use dash as no other widget would allow to show input and dropdown menus\n",
    "\n",
    "# creating the layout\n",
    "# initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "dropdown_option_labels = ['HDBSCAN', 'K-means', 'Agglomerative Hierarchical', 'Gaussian Mixture Models', 'DBSCAN']\n",
    "dropdown_option_values = ['HDBSCAN0', 'KMEANS', 'AGGLO_HIER', 'GMM', 'DBSCAN']\n",
    "\n",
    "app.layout = html.Div(id = 'parent', children = [\n",
    "\n",
    "    # setting the graph component\n",
    "    dcc.Graph(id = 'scatter-plot'),\n",
    "\n",
    "    html.Div([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div(\n",
    "                dbc.Label(['Choose clustering algorithm:'], style={'font-weight': 'bold'})\n",
    "            ), width=6, lg=3),\n",
    "\n",
    "            dbc.Col(html.Div(\n",
    "                dcc.Dropdown(id = 'dropdown',\n",
    "                             options = [{'label':i, 'value':j} for i, j in zip(dropdown_option_labels, dropdown_option_values)],\n",
    "                             value = 'KMEANS',\n",
    "                             style = {'width':'50%', 'verticalAlign': 'middle'}, # , 'height':'auto',  'font-size' : '12px'\n",
    "                             placeholder = 'Select a clustering algorithm...')\n",
    "            ), width={\"size\": 3, \"order\": \"last\", \"offset\": 1}, lg=3)\n",
    "        ]),\n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.Div(\n",
    "                dbc.Label(['Input number of clusters: '], style={'font-weight': 'bold'})\n",
    "            ), width=6, lg=3),\n",
    "\n",
    "            dbc.Col(html.Div(\n",
    "                dcc.Input(id='ncluster-input', value='2', type='text')\n",
    "            ), width=6, lg=3)\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "])\n",
    "\n",
    "## 2 input components corresponding to input and dropdown respectively\n",
    "## 1 output component corresponding to the scatter plot\n",
    "@app.callback(Output(component_id='scatter-plot', component_property='figure'),\n",
    "              [Input(component_id='ncluster-input', component_property='value'),\n",
    "               Input(component_id='dropdown', component_property= 'value')])\n",
    "\n",
    "def graph_update(n_cluster_value, clust_method_value):\n",
    "    # filtering based on the input and dropdown selection\n",
    "    if clust_method_value == 'HDBSCAN0':\n",
    "        cluster_method = 'HDBSCAN'\n",
    "        clustering_method = clust_method_value\n",
    "        what2display = 'block'\n",
    "    elif clust_method_value == 'DBSCAN':\n",
    "        what2display = 'none'\n",
    "        cluster_method = clust_method_value\n",
    "        clustering_method = clust_method_value + '_D' + n_cluster_value\n",
    "    else:\n",
    "        what2display = 'none'\n",
    "        clustering_method = clust_method_value + '_K' + n_cluster_value\n",
    "        if clust_method_value == 'AGGLO_HIER':\n",
    "            cluster_method = 'Agglomerative Hierarchical'\n",
    "        elif clust_method_value == 'KMEANS':\n",
    "            cluster_method = 'K-means'\n",
    "        elif clust_method_value == 'GMM':\n",
    "            cluster_method = 'Gaussian Mixture Models'\n",
    "\n",
    "    print(cluster_method)\n",
    "    print(clustering_method)\n",
    "    # compute the default clustering solution with K-means, k = 2\n",
    "    clustering_solution = eeg_class.perform_clustering(df_pca, clustering_method)\n",
    "    eval_list = eeg_class.cluster_evaluation_indexes(df_pca, clustering_solution, distances_matrix)\n",
    "    explained_variance = sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    pca_title = 'PCA feature reduction<br>(explained variance = ' + str(round(explained_variance*100, 1)) + '%)'\n",
    "    cluster_title = cluster_method + ', k=' + n_cluster_value + ' clustering solution<br> '\n",
    "    fig = make_subplots(rows=1, cols=2, specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "                        subplot_titles=(pca_title, cluster_title),\n",
    "                        shared_yaxes=False, shared_xaxes=False, horizontal_spacing=0.05)\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=df_pca['PC1'], y=df_pca['PC2'], z=df_pca['PC3'], mode='markers',\n",
    "                               marker=dict(size=3, color=time_vector, colorscale='Viridis', showscale=True,\n",
    "                                           colorbar=dict(len=1, x=-0.15, y=0.45, titleside='right', thickness=20,\n",
    "                                                         title='<b>Time before seizure (' + get_time_vector +')<b>', outlinewidth=1, titlefont=dict(size=12), tickmode='array',\n",
    "                                                         tickvals=tickvals_lst, ticktext=ticktext_lst,\n",
    "                                                         ticklabelposition='outside'))))\n",
    "\n",
    "    # plot the clustering solution\n",
    "    fig.add_trace(go.Scatter3d(x=df_pca['PC1'], y=df_pca['PC2'], z=df_pca['PC3'], mode='markers',\n",
    "                               marker=dict(size=3, color=clustering_solution, colorscale='Viridis')), row=1, col=2)\n",
    "\n",
    "    fig.update_layout(width=1000, margin=dict(l=100, r=150, b=70, t=70),\n",
    "                      title=dict(text='<b>Patient ' + str(patient_index) + ', seizure ' + str(seizure_index),\n",
    "                                 y=0.98, x=0.47, xanchor='center', yanchor='top'),\n",
    "                      template='plotly_white', showlegend=False,\n",
    "                      scene = dict(xaxis_title='C1', yaxis_title='C2',zaxis_title='C3'),\n",
    "                      scene2 = dict(xaxis_title='C1', yaxis_title='C2',zaxis_title='C3'))\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False,\n",
    "                   # mode='inline'\n",
    "                   )\n",
    "\n",
    "stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "list_perplexity = np.arange(10, 110, 10)\n",
    "tc1 = []\n",
    "tc2 = []\n",
    "tc3 = []\n",
    "dic_tsne_clust_results = []\n",
    "for perplexity in list_perplexity:\n",
    "\n",
    "    df_tsne, array_tsne = eeg_class.tsne_feature_reduction(df_seizure_data, perplexity)\n",
    "\n",
    "    tc1.append(array_tsne[:, 0])\n",
    "    tc2.append(array_tsne[:, 1])\n",
    "    tc3.append(array_tsne[:, 2])\n",
    "\n",
    "    # get pairwise distances between samples\n",
    "    distances_matrix = pairwise_distances(df_tsne)\n",
    "\n",
    "    # start_time = datetime.now()\n",
    "    for cm in clust_methods:\n",
    "        # print({p}, {s}, {cm}, 'tsne', {perplexity})\n",
    "        clustering_solution = eeg_class.perform_clustering(df_tsne, cm)\n",
    "\n",
    "        eval_list = eeg_class.cluster_evaluation_indexes(df_tsne, clustering_solution, distances_matrix)\n",
    "        dic_tsne_clust_results.append([perplexity, cm.lower()] + eval_list)\n",
    "\n",
    "lst_string_perplexity = list(map(str, list_perplexity.tolist()))\n",
    "df_tc1 = pd.DataFrame(tc1).transpose()\n",
    "df_tc1.columns = lst_string_perplexity\n",
    "df_tc2 = pd.DataFrame(tc2).transpose()\n",
    "df_tc2.columns = lst_string_perplexity\n",
    "df_tc3 = pd.DataFrame(tc3).transpose()\n",
    "df_tc3.columns = lst_string_perplexity\n",
    "df_tsne_clust_results = pd.DataFrame(dic_tsne_clust_results, columns=['perplexity'] + clust_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "n_neighbours_vec = np.arange(10, 110, 10)\n",
    "min_dist_vec = np.round(np.arange(0.1, 1.0, 0.1), 2)\n",
    "uc1 = []\n",
    "uc2 = []\n",
    "uc3 = []\n",
    "dic_umap_clust_results = []\n",
    "lst_header = []\n",
    "for n_neighbours in n_neighbours_vec:\n",
    "    for min_dist in min_dist_vec:\n",
    "\n",
    "        lst_header.append(str(n_neighbours) + '_' + str(min_dist))\n",
    "\n",
    "        df_umap, array_umap = eeg_class.umap_feature_reduction(df_seizure_data, n_neighbours, min_dist)\n",
    "\n",
    "        uc1.append(array_umap[:, 0])\n",
    "        uc2.append(array_umap[:, 1])\n",
    "        uc3.append(array_umap[:, 2])\n",
    "\n",
    "        # get pairwise distances between samples\n",
    "        distances_matrix = pairwise_distances(df_umap)\n",
    "\n",
    "        # start_time = datetime.now()\n",
    "        for cm in clust_methods:\n",
    "            # print({p}, {s}, {cm}, 'umap', {n_neighbours}, {min_dist})\n",
    "            clustering_solution = eeg_class.perform_clustering(df_umap, cm)\n",
    "\n",
    "            eval_list = eeg_class.cluster_evaluation_indexes(df_umap, clustering_solution, distances_matrix)\n",
    "\n",
    "            dic_umap_clust_results.append([n_neighbours, min_dist, cm.lower()] + eval_list)\n",
    "            # print('end clustering')\n",
    "        # print('end all clustering methods in umap')\n",
    "\n",
    "df_uc1 = pd.DataFrame(uc1).transpose()\n",
    "df_uc1.columns = lst_header\n",
    "df_uc2 = pd.DataFrame(uc2).transpose()\n",
    "df_uc2.columns = lst_header\n",
    "df_uc3 = pd.DataFrame(uc3).transpose()\n",
    "df_uc3.columns = lst_header\n",
    "\n",
    "df_umap_clust_results = pd.DataFrame(dic_umap_clust_results, columns=['n_neighbors', 'min_dist'] + clust_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
